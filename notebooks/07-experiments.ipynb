{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102e8672",
   "metadata": {},
   "source": [
    "# 07 - MLflow Experiments\n",
    "\n",
    "Run and compare CatBoost, Bayesian, and Linear baselines with unified MLflow logging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a26dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import shutil\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from pathlib import Path\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sympy import prime\n",
    "\n",
    "from nba_ingame_prob.consts import proj_paths\n",
    "from nba_ingame_prob.training.hpo import (\n",
    "    replicate_bayesian_best, \n",
    "    replicate_catboost_best, \n",
    "    replicate_linear_logistic_best, \n",
    "    replicate_linear_regression_best,\n",
    "    run_study_bayesian, \n",
    "    run_study_catboost, \n",
    "    run_study_linear_logistic, \n",
    "    run_study_linear_regression,\n",
    "    run_hpo_with_override,\n",
    "    replicate_with_custom_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb07f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"linear_regression\": {\n",
    "        \"hpo_fn\": run_study_linear_regression,\n",
    "        \"replicate_fn\": replicate_linear_regression_best,\n",
    "        \"config\": proj_paths.config.linear_regression,\n",
    "    },\n",
    "    \"linear_logistic\": {\n",
    "        \"hpo_fn\": run_study_linear_logistic,\n",
    "        \"replicate_fn\": replicate_linear_logistic_best,\n",
    "        \"config\": proj_paths.config.linear_logistic,\n",
    "    },\n",
    "    \"catboost\": {\n",
    "        \"hpo_fn\": run_study_catboost,\n",
    "        \"replicate_fn\": replicate_catboost_best,\n",
    "        \"config\": proj_paths.config.catboost,\n",
    "    },\n",
    "    \"bayesian\": {\n",
    "        \"hpo_fn\": run_study_bayesian,\n",
    "        \"replicate_fn\": replicate_bayesian_best,\n",
    "        \"config\": proj_paths.config.bayesian,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359b341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HPO Results Summary:\n",
      "linear_regression: 0.4489 | {'alpha': 99.94523496627072}\n",
      "linear_logistic: 0.4388 | {'C': 0.0036383924346184548}\n",
      "catboost: 0.4047 | {'learning_rate': 0.09636223593149941, 'max_depth': 5, 'iterations': 1400, 'l2_leaf_reg': 0.4290344235973468, 'colsample_bylevel': 0.9433600798423123, 'subsample': 0.5369048376010586, 'max_bin': 91}\n",
      "bayesian: 0.4050 | {'learning_rate': 0.002178737122149179, 'weight_decay': 1.2171989575527562e-06, 'lr_gamma': 0.8354521167934316, 'team_hidden_dim': 4, 'team_layers': 3, 'res_hidden_dim': 22, 'res_layers': 2, 'embedding_dim': None}\n"
     ]
    }
   ],
   "source": [
    "hpo_results = {}\n",
    "n_trials = 50\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    hpo_fn = model_info[\"hpo_fn\"]\n",
    "    config_path = model_info[\"config\"]\n",
    "    experiment_name = \"NBAGames-HPO\"\n",
    "    \n",
    "    study = run_hpo_with_override(\n",
    "        hpo_fn, config_path, \n",
    "        study_name=f\"{model_name}-study\", \n",
    "        experiment_name=experiment_name, \n",
    "        n_trials=n_trials, \n",
    "        reserve_validation=True\n",
    "    )\n",
    "    \n",
    "    hpo_results[model_name] = {\n",
    "        \"study\": study,\n",
    "        \"best_params\": study.best_params,\n",
    "        \"best_value\": study.best_value,\n",
    "    }\n",
    "    \n",
    "clear_output(wait=True)\n",
    "print(\"\\nHPO Results Summary:\")\n",
    "for model_name, hpo_result in hpo_results.items():\n",
    "    print(f\"{model_name}: {hpo_result['best_value']:.4f} | {hpo_result['best_params']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d4510c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SEEDS Results Summary:\n",
      "linear_regression: 0.4489 ± 0.0000 | Best: 0.4489 @ seed 2\n",
      "linear_logistic: 0.4388 ± 0.0000 | Best: 0.4388 @ seed 2\n",
      "catboost: 0.4145 ± 0.0057 | Best: 0.4047 @ seed 47\n",
      "bayesian: 0.4116 ± 0.0058 | Best: 0.4017 @ seed 5\n"
     ]
    }
   ],
   "source": [
    "n_trials = 30\n",
    "\n",
    "primes = [prime(i) for i in range(1, 30)]\n",
    "seed_study_results = {}\n",
    "\n",
    "for model_name, result in hpo_results.items():\n",
    "    print(f\"Running SEEDS evaluation for {model_name}...\")\n",
    "    study = result[\"study\"]\n",
    "    config_path = models[model_name][\"config\"]\n",
    "    replicate_fn = models[model_name][\"replicate_fn\"]\n",
    "    experiment_name = \"NBAGames-SEEDS\"\n",
    "    \n",
    "    # Use helper function with explicit reserve_validation=True and get summary\n",
    "    results, summary = replicate_with_custom_config(\n",
    "        replicate_fn, config_path, study, \n",
    "        seeds=primes, \n",
    "        experiment_name=experiment_name, \n",
    "        reserve_validation=True\n",
    "    )\n",
    "    \n",
    "    seed_study_results[model_name] = summary\n",
    "    print(f\"  Mean: {summary['mean']:.4f} ± {summary['std']:.4f}\")\n",
    "    print(f\"  Best seed: {summary['best_seed']} (metric: {summary['best_metric']:.4f})\")\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"\\nSEEDS Results Summary:\")\n",
    "for model_name, summary in seed_study_results.items():\n",
    "    print(f\"{model_name}: {summary['mean']:.4f} ± {summary['std']:.4f} | Best: {summary['best_metric']:.4f} @ seed {summary['best_seed']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2676cd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL Results Summary:\n",
      "linear_regression: 0.5024\n",
      "linear_logistic: 0.5029\n",
      "catboost: 0.4739\n",
      "bayesian: 0.4757\n",
      "\n",
      "Best model: catboost (log loss: 0.4739)\n"
     ]
    }
   ],
   "source": [
    "# FINAL Phase: Evaluate best seed on test set (reserve_validation=False)\n",
    "final_eval_results = {}\n",
    "\n",
    "for model_name in models.keys():\n",
    "    print(f\"Running FINAL evaluation for {model_name}...\")\n",
    "    study = hpo_results[model_name][\"study\"]\n",
    "    config_path = models[model_name][\"config\"]\n",
    "    replicate_fn = models[model_name][\"replicate_fn\"]\n",
    "    best_seed = seed_study_results[model_name][\"best_seed\"]\n",
    "    experiment_name = \"NBAGames-FINAL\"\n",
    "    \n",
    "    # Use helper function with explicit reserve_validation=False for test evaluation\n",
    "    results, summary = replicate_with_custom_config(\n",
    "        replicate_fn, config_path, study, \n",
    "        seeds=[best_seed], \n",
    "        experiment_name=experiment_name, \n",
    "        reserve_validation=False\n",
    "    )\n",
    "    \n",
    "    final_metric = summary['best_metric']  # Should be the only metric since single seed\n",
    "    final_eval_results[model_name] = {\"final_metric\": final_metric}\n",
    "    print(f\"  Test metric: {final_metric:.4f}\")\n",
    "\n",
    "# Find best model based on test performance\n",
    "best_final_model = min(final_eval_results.items(), key=lambda x: x[1][\"final_metric\"])  # Lower log loss is better\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"\\nFINAL Results Summary:\")\n",
    "for model_name, result in final_eval_results.items():\n",
    "    print(f\"{model_name}: {result['final_metric']:.4f}\")\n",
    "print(f\"\\nBest model: {best_final_model[0]} (log loss: {best_final_model[1]['final_metric']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df0ed179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying best configuration for each model class to production...\n",
      "\n",
      "Deploying linear_regression...\n",
      "  Downloading artifacts from FINAL run: be6127461d484f6a8713a0e493fea545\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927e9689f9804897b203062429b6cf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Copying run_config.yaml...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/linear_regression/run_config.yaml\n",
      "    Copying model.pkl...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/linear_regression/model.pkl\n",
      "    Copying scalers.pkl...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/linear_regression/scalers.pkl\n",
      "  ✓ linear_regression deployed (3 files, seed: 2, test log loss: 0.5024)\n",
      "\n",
      "Deploying linear_logistic...\n",
      "  Downloading artifacts from FINAL run: f9888c52fa1147649f9e5a0c887058ec\n",
      "  Downloading artifacts from FINAL run: f9888c52fa1147649f9e5a0c887058ec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8384658aa0b14bcb9bdc309b834201ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Copying run_config.yaml...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/linear_logistic/run_config.yaml\n",
      "    Copying model.pkl...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/linear_logistic/model.pkl\n",
      "    Copying scalers.pkl...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/linear_logistic/scalers.pkl\n",
      "  ✓ linear_logistic deployed (3 files, seed: 2, test log loss: 0.5029)\n",
      "\n",
      "Deploying catboost...\n",
      "  Downloading artifacts from FINAL run: c6d6e6ebfc034450952eedcf73a7ed5c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c1dae6c10b4a158fedd610ee73cebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Copying run_config.yaml...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/catboost/run_config.yaml\n",
      "    Copying model.cbm...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/catboost/model.cbm\n",
      "    Copying scalers.pkl...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/catboost/scalers.pkl\n",
      "  ✓ catboost deployed (3 files, seed: 47, test log loss: 0.4739)\n",
      "\n",
      "Deploying bayesian...\n",
      "  Downloading artifacts from FINAL run: 7d0cd2fc6b544388a27ee252670d25ae\n",
      "  Downloading artifacts from FINAL run: 7d0cd2fc6b544388a27ee252670d25ae\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816c1c8487ec423b85b26b3c528b9d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Copying run_config.yaml...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/bayesian/run_config.yaml\n",
      "    Copying model.pth...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/bayesian/model.pth\n",
      "    Copying model_init.yaml...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/bayesian/model_init.yaml\n",
      "    Copying scalers.pkl...\n",
      "      -> /workspaces/nba-ingame-prob/models/production/bayesian/scalers.pkl\n",
      "  ✓ bayesian deployed (4 files, seed: 5, test log loss: 0.4757)\n",
      "\n",
      "Production deployment complete!\n",
      "All model artifacts saved to: /workspaces/nba-ingame-prob/models/production\n",
      "\n",
      "Deployed models:\n",
      "  linear_regression: seed 2, test log loss 0.5024\n",
      "  linear_logistic: seed 2, test log loss 0.5029\n",
      "  catboost: seed 47, test log loss 0.4739\n",
      "  bayesian: seed 5, test log loss 0.4757\n",
      "\n",
      "Overall best model: catboost (log loss: 0.4739)\n"
     ]
    }
   ],
   "source": [
    "production_dir = proj_paths.models / \"production\"\n",
    "production_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Deploying best configuration for each model class to production...\\n\")\n",
    "\n",
    "client = MlflowClient()\n",
    "final_experiment = mlflow.get_experiment_by_name(\"NBAGames-FINAL\")\n",
    "\n",
    "for model_name in models.keys():\n",
    "    print(f\"Deploying {model_name}...\")\n",
    "    \n",
    "    best_seed = seed_study_results[model_name][\"best_seed\"]\n",
    "    test_metric = final_eval_results[model_name][\"final_metric\"]\n",
    "    \n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[final_experiment.experiment_id],\n",
    "        filter_string=f\"tags.seed_study = '{model_name}' AND tags.seed = '{best_seed}'\",\n",
    "        max_results=1\n",
    "    )\n",
    "    \n",
    "    if not runs:\n",
    "        print(f\"  No FINAL run found for {model_name} with seed {best_seed}\")\n",
    "        continue\n",
    "        \n",
    "    final_run = runs[0]\n",
    "    print(f\"  Downloading artifacts from FINAL run: {final_run.info.run_id}\")\n",
    "    \n",
    "    artifacts_dir = client.download_artifacts(final_run.info.run_id, \"artifacts\")\n",
    "    artifacts_path = Path(artifacts_dir)\n",
    "    \n",
    "    downloaded_files = []\n",
    "    \n",
    "    if artifacts_path.exists():\n",
    "        for file_path in artifacts_path.rglob(\"*\"):\n",
    "            if file_path.is_file() and file_path.suffix in ('.pth', '.pkl', '.joblib', '.cbm', '.yaml'):\n",
    "                print(f\"    Copying {file_path.name}...\")\n",
    "                target_path = production_dir / model_name / file_path.name\n",
    "                target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy2(file_path, target_path)\n",
    "                downloaded_files.append(target_path)\n",
    "                print(f\"      -> {target_path}\")\n",
    "    \n",
    "    print(f\"  ✓ {model_name} deployed ({len(downloaded_files)} files, seed: {best_seed}, test log loss: {test_metric:.4f})\\n\")\n",
    "\n",
    "print(\"Production deployment complete!\")\n",
    "print(f\"All model artifacts saved to: {production_dir}\")\n",
    "print(\"\\nDeployed models:\")\n",
    "for model_name in models.keys():\n",
    "    test_metric = final_eval_results[model_name][\"final_metric\"]\n",
    "    best_seed = seed_study_results[model_name][\"best_seed\"]\n",
    "    print(f\"  {model_name}: seed {best_seed}, test log loss {test_metric:.4f}\")\n",
    "\n",
    "print(f\"\\nOverall best model: {best_final_model[0]} (log loss: {best_final_model[1]['final_metric']:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-ingame-prob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
