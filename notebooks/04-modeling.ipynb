{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-11T18:45:05.282381Z",
     "iopub.status.busy": "2024-12-11T18:45:05.281945Z",
     "iopub.status.idle": "2024-12-11T18:45:06.547388Z",
     "shell.execute_reply": "2024-12-11T18:45:06.546109Z",
     "shell.execute_reply.started": "2024-12-11T18:45:05.282329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import shutil\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from functools import partial\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nba_betting_ai.consts import proj_paths\n",
    "from nba_betting_ai.data.processing import add_prefix\n",
    "from nba_betting_ai.model.bayesian import BayesianResultPredictor\n",
    "from nba_betting_ai.model.inputs import prepare_scalers\n",
    "from nba_betting_ai.training.dataset import NBADataset\n",
    "from nba_betting_ai.training.pipeline import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats_season = [\n",
    "    'season_games',\n",
    "    'season_wins', 'season_pts_for', 'season_pts_against',\n",
    "    'season_wins_avg', 'season_pts_for_avg', 'season_pts_against_avg',\n",
    "]\n",
    "team_stats_last_5 = [\n",
    "    'last_5_wins',\n",
    "    'last_5_pts_for_avg', 'last_5_pts_against_avg',\n",
    "    'last_5_pts_for_total', 'last_5_pts_against_total',\n",
    "]\n",
    "target_general = ['away_win', 'score_final_diff']\n",
    "target_team = 'score_final'\n",
    "identification_cols = [\n",
    "    'game_id', 'home_team_abbreviation', 'away_team_abbreviation',\n",
    "]\n",
    "other_features = [\n",
    "    'home_score', 'away_score', 'time_remaining', 'score_diff'\n",
    "]\n",
    "\n",
    "prefix_home = partial(add_prefix, prefix='home', return_type='list')\n",
    "prefix_away = partial(add_prefix, prefix='away', return_type='list')\n",
    "all_features = identification_cols \\\n",
    "            + target_general \\\n",
    "            + prefix_home([target_team]) + prefix_away([target_team]) \\\n",
    "            + prefix_home(team_stats_season) + prefix_away(team_stats_season) \\\n",
    "            + prefix_home(team_stats_last_5) + prefix_away(team_stats_last_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {\n",
    "    'seasons': 2,\n",
    "    'seed': 66,\n",
    "    'test_size': 0.2,\n",
    "    'n': 20,\n",
    "    'frac': None\n",
    "}\n",
    "\n",
    "team_features = [\n",
    "    'away_season_wins_avg', 'home_season_wins_avg',\n",
    "    'away_season_pts_diff_avg', 'away_last_5_pts_diff_avg',\n",
    "    'home_season_pts_diff_avg', 'home_last_5_pts_diff_avg'\n",
    "]\n",
    "target_general = ['final_score_diff']\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'lr_gamma': 0.85,\n",
    "    'batch_size': 128,\n",
    "    'epochs': 300,\n",
    "    'eval_freq': 10\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    'embedding_dim': 4, #8,\n",
    "    'team_hidden_dim': 16, # 32,\n",
    "    'team_layers': 3,\n",
    "    'res_hidden_dim': 16, #32,\n",
    "    'res_layers': 4,\n",
    "    'time_scaling': True\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'features': team_features,\n",
    "    'target': target_general,\n",
    "    'training': {\n",
    "        'params': params,\n",
    "        'model_config': model_config\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping\n",
    "from omegaconf import OmegaConf\n",
    " \n",
    "def convert_flatten(d, parent_key ='', sep ='.'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    " \n",
    "        if isinstance(v, MutableMapping):\n",
    "            items.extend(convert_flatten(v, new_key, sep = sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "config = OmegaConf.load(proj_paths.config.default)\n",
    "config_archive = proj_paths.config.default.with_stem(f'config-{now}')\n",
    "\n",
    "scalers_path = proj_paths.output / 'scalers.pkl'\n",
    "\n",
    "data_prepared = prepare_data(**config['data_params'])\n",
    "scalers = prepare_scalers(data_prepared.X_train, team_features, scalers_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/27 20:43:19 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n",
      "2025/01/27 20:43:19 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "loss: 1.5094:   0%|          | 60/76200 [00:02<44:30, 28.52it/s]\n",
      "2025/01/27 20:43:22 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/01/27 20:43:22 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bayesian_model-20250127-204316 at: http://mlflow:5000/#/experiments/664344747479239756/runs/ef2460b794374aa283a6c0c4cb85a430\n",
      "ðŸ§ª View experiment at: http://mlflow:5000/#/experiments/664344747479239756\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     51\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 52\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n",
      "File \u001b[0;32m/workspaces/nba-betting-ai/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/workspaces/nba-betting-ai/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/workspaces/nba-betting-ai/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/workspaces/nba-betting-ai/nba_betting_ai/training/dataset.py:72\u001b[0m, in \u001b[0;36mNBADataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     68\u001b[0m     data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_team\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_team(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhome_team\u001b[38;5;241m.\u001b[39miloc[idx]), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32),\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_team\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_team(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maway_team\u001b[38;5;241m.\u001b[39miloc[idx]), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32),\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_data\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhome_data\u001b[38;5;241m.\u001b[39miloc[idx]\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[0;32m---> 72\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_data\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maway_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiff\u001b[38;5;241m.\u001b[39miloc[idx], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_remaining\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_remaining\u001b[38;5;241m.\u001b[39miloc[idx], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39miloc[idx]\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m     76\u001b[0m     }\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "now = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "config = OmegaConf.load(proj_paths.config.default)\n",
    "config_archive = proj_paths.config.default.with_stem(f'config-{now}')\n",
    "\n",
    "scalers_path = proj_paths.output / 'scalers.pkl'\n",
    "\n",
    "data_prepared = prepare_data(**config['data_params'])\n",
    "scalers = prepare_scalers(data_prepared.X_train, team_features, scalers_path)\n",
    "\n",
    "train_dataset = NBADataset(team_features, target_general, data_prepared.X_train, data_prepared.teams, scalers)\n",
    "test_dataset = NBADataset(team_features, target_general, data_prepared.X_test, data_prepared.teams, scalers)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BayesianResultPredictor(\n",
    "    team_count=len(data_prepared.teams),\n",
    "    team_features=len(team_features)//2,\n",
    "    **model_config\n",
    ").to(device)\n",
    "learning_rate = params['learning_rate']\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = params.get('lr_gamma', 1.0))\n",
    "const = 0.5 * torch.log(2 * torch.tensor(torch.pi, dtype=torch.float64)).to(device)\n",
    "\n",
    "create_experiment = mlflow.get_experiment_by_name(config['experiment_name']) is None\n",
    "if create_experiment:\n",
    "    mlflow.create_experiment(\n",
    "        name=config['experiment_name'],\n",
    "        tags={\n",
    "            'author': 'Tom Bukic',\n",
    "            'company': 'accelerate.ai'\n",
    "        }\n",
    "    )\n",
    "    create_experiment = False\n",
    "\n",
    "mlflow.set_experiment(config['experiment_name'])\n",
    "\n",
    "run_name = f'bayesian_model-{now}'\n",
    "best_loss = float('inf')\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    flat_config = convert_flatten(config)\n",
    "    mlflow.log_params(flat_config)\n",
    "    mlflow.log_artifact(scalers_path)\n",
    "    mlflow.log_artifact(proj_paths.config.default)\n",
    "    shutil.copy(proj_paths.config.default.as_posix(), config_archive.as_posix())\n",
    "    last_update = 0\n",
    "    with tqdm(total=params['epochs']*len(train_loader), desc='Training Progress') as progress_bar:\n",
    "        for epoch in range(params['epochs']):\n",
    "            model.train()\n",
    "            for i, data in enumerate(train_loader):\n",
    "                step = epoch * params['batch_size'] + i\n",
    "                data = {\n",
    "                    k: v.to(device)\n",
    "                    for k, v in data.items()\n",
    "                }\n",
    "                target = data.pop('y')\n",
    "                optimizer.zero_grad()\n",
    "                output = model(**data)\n",
    "                mu, logvar = torch.chunk(output, 2, dim=-1)\n",
    "                logvar = torch.clamp(logvar, min=-10, max=10)\n",
    "                loss = const + logvar + (target - mu)**2 / torch.exp(logvar)\n",
    "                loss = torch.mean(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if step % 20 == 0:\n",
    "                    progress_bar.set_description(f'loss: {loss:.4f}')\n",
    "                    progress_bar.update(20)\n",
    "                    mlflow.log_metric('train_loss', loss.item(), step=step)\n",
    "                    last_update = step\n",
    "            scheduler.step(epoch=epoch)\n",
    "            if last_update < step:\n",
    "                progress_bar.set_description(f'loss: {loss:.4f}')\n",
    "                progress_bar.update(step - last_update)\n",
    "                last_update = step\n",
    "            mlflow.log_metric('train_loss', loss.item(), step=step)\n",
    "            if epoch % params['eval_freq'] != 0 and epoch < params['epochs'] - 1:\n",
    "                continue\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            total_loss = 0\n",
    "            avg_var = 0\n",
    "            n = 0\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(test_loader):\n",
    "                    data = {\n",
    "                        k: v.to(device)\n",
    "                        for k, v in data.items()\n",
    "                    }\n",
    "                    target = data.pop('y')\n",
    "                    output = model(**data)\n",
    "                    mu, logvar = torch.chunk(output, 2, dim=-1)\n",
    "                    logvar = torch.clamp(logvar, min=-10, max=10)\n",
    "                    var = torch.exp(logvar)\n",
    "                    loss = const + logvar + (target - mu)**2 / var\n",
    "                    total_loss += torch.mean(loss)\n",
    "                    next_n = n + len(target)\n",
    "                    avg_var = avg_var*(n/next_n) + torch.mean(var).item()*(len(target)/next_n)\n",
    "                    n = next_n\n",
    "                    \n",
    "                    total += target.size(0)\n",
    "                    correct += (mu*target >= 0).sum().item()\n",
    "            avg_loss = total_loss.item() / len(test_loader)\n",
    "            accuracy = correct / n\n",
    "            model_path = proj_paths.output / f'bayesian_model-{now}-loss_{str(avg_loss).replace('.', '_')}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            mlflow.log_artifact(model_path)\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                best_model_path = proj_paths.output / 'bayesian_model_best.pth'\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                mlflow.log_artifact(best_model_path)\n",
    "            mlflow.log_metric('eval_accuracy', accuracy, step=step)\n",
    "            mlflow.log_metric('eval_var', avg_var, step=step)\n",
    "            mlflow.log_metric('eval_loss', avg_loss, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2151223,
     "sourceId": 4088094,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
